# -*- coding: utf-8 -*-
"""Topology.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BnHxsKnG7VxwwFQlrlFAjGveAgc7_JAI
"""

from google.colab import drive
drive.mount('/content/drive')



# Step 1: Import Library & Read Data
import geopandas as gpd
import pandas as pd
import numpy as np
from shapely.geometry import Polygon, mapping
from shapely.ops import unary_union
from sklearn.cluster import DBSCAN
from collections import defaultdict
import os
import networkx as nx
import json
from bokeh.io import output_file, save
from bokeh.models import GeoJSONDataSource, HoverTool, WMTSTileSource
from bokeh.plotting import figure
from bokeh.palettes import Category20
from bokeh.transform import factor_cmap

# Step 2: Read data and convert coordinates
import geopandas as gpd
import pandas as pd
import numpy as np

survey_df = pd.read_csv("./drive/MyDrive/apply_data_science/survey_data/survey_responses.csv")
gdf = gpd.read_file("./drive/MyDrive/apply_data_science/survey_data/downloaded_data_polygons.gpkg")

# merge
gdf = gdf.merge(survey_df, on="id", how="left")

# Unified projection to Web Mercator (Google Maps basemap)
gdf = gdf.to_crs(epsg=3857)

# Filter out records where geometry is null
gdf = gdf[gdf.geometry.notnull()].copy()
gdf["is_valid_geom"] = gdf.geometry.is_valid

# print
print("total：", len(gdf))
print("valid geometry ：", gdf.is_valid_geom.sum())
print("invaild geometry ：", (~gdf.is_valid_geom).sum())

gdf.head()

# Calculate area, perimeter, shape index, center point only for legal geometry
gdf.loc[gdf.is_valid_geom, "area"] = gdf.loc[gdf.is_valid_geom, "geometry"].area
gdf.loc[gdf.is_valid_geom, "perimeter"] = gdf.loc[gdf.is_valid_geom, "geometry"].length
gdf.loc[gdf.is_valid_geom, "shape_index"] = (
    gdf.loc[gdf.is_valid_geom, "perimeter"] / (4 * np.sqrt(gdf.loc[gdf.is_valid_geom, "area"]))
)
gdf.loc[gdf.is_valid_geom, "centroid"] = gdf.loc[gdf.is_valid_geom, "geometry"].centroid
gdf.loc[gdf.is_valid_geom, "x"] = gdf.loc[gdf.is_valid_geom, "centroid"].x
gdf.loc[gdf.is_valid_geom, "y"] = gdf.loc[gdf.is_valid_geom, "centroid"].y

# Category field cleaning (keep &, do not remove symbols)
gdf["main_category"] = gdf["Category"].fillna("Unknown").str.strip()

# Create location_group (only process legal geometry)
buffer_radius = 20
gdf_valid = gdf[gdf.is_valid_geom].copy()
gdf_valid["buffer"] = gdf_valid.geometry.buffer(buffer_radius)
joined = gpd.sjoin(
    gdf_valid[["id", "buffer"]].set_geometry("buffer"),
    gdf_valid[["id", "geometry"]],
    how="left", predicate="intersects"
)
joined = joined[joined["id_left"] != joined["id_right"]]

def jaccard_similarity(geom1, geom2):
    try:
        inter = geom1.intersection(geom2).area
        union = geom1.union(geom2).area
        return inter / union if union > 0 else 0
    except:
        return 0

G = nx.Graph()
for _, row in joined.iterrows():
    id1 = row["id_left"]
    id2 = row["id_right"]
    poly1 = gdf_valid.loc[gdf_valid["id"] == id1].geometry.values[0]
    poly2 = gdf_valid.loc[gdf_valid["id"] == id2].geometry.values[0]
    sim = jaccard_similarity(poly1, poly2)
    if sim >= 0.3:
        G.add_edge(id1, id2)

id_to_group = {}
for i, component in enumerate(nx.connected_components(G)):
    for geom_id in component:
        id_to_group[geom_id] = i
gdf_valid["location_group"] = gdf_valid["id"].map(id_to_group)

# No. geo_subclass (valid and invalid separated)
geo_counter = defaultdict(int)
gdf["geo_subclass"] = None  # 初始化

category_prefix = {
    "Fences & Barriers": "F",
    "Planting": "PL",
    "Parking": "P",
    "Bike use": "B",
    "Restroom": "R",
    "Recreation Area": "RE",
    "Pedestrian Use": "PE",
    "Wayfinding&Signage": "W",
    "Water Services": "WS"
}

def standardize_category(cat):
    if pd.isna(cat):
        return "Unknown"
    cat = str(cat).strip()
    for key in category_prefix.keys():
        if key.lower().replace(" ", "") in cat.lower().replace(" ", ""):
            return key
    return cat

gdf["main_category"] = gdf["Category"].apply(standardize_category)
gdf_valid["main_category"] = gdf["main_category"]

# Assign geo_subclass with location_group of valid geometry
for cat in gdf["main_category"].unique():
    clean_cat = cat.strip()
    prefix = category_prefix.get(clean_cat, clean_cat[:2].upper())

    # Valid + grouped parts
    sub_valid = gdf_valid[gdf_valid["main_category"] == cat]
    for group in sorted(sub_valid["location_group"].dropna().unique()):
        geo_counter[prefix] += 1
        label = f"{prefix}{geo_counter[prefix]:02d}"

        ids_in_group = sub_valid[sub_valid["location_group"] == group]["id"]
        mask = (gdf["id"].isin(ids_in_group))
        gdf.loc[mask, "geo_subclass"] = label

    # Invalid geometry part
    invalid_mask = (gdf["main_category"] == cat) & (~gdf.is_valid_geom)
    if invalid_mask.any():
        geo_counter[prefix] += 1
        label = f"{prefix}{geo_counter[prefix]:02d}"
        gdf.loc[invalid_mask, "geo_subclass"] = label
        gdf.loc[invalid_mask, "location_group"] = -1

# Handling of unnumbered valid figures
unassigned_valid = gdf[gdf["geo_subclass"].isna() & gdf["is_valid_geom"]]

# Assign numbers to valid unnumbered shapes
for _, row in unassigned_valid.iterrows():
    cat = row["main_category"]
    clean_cat = cat.strip()
    prefix = category_prefix.get(clean_cat, clean_cat[:2].upper())

    geo_counter[prefix] += 1
    label = f"{prefix}{geo_counter[prefix]:02d}"

    # update
    gdf.loc[gdf["id"] == row["id"], "geo_subclass"] = label

# print
print(gdf["geo_subclass"].value_counts())
unassigned = gdf[gdf.is_valid_geom & gdf["geo_subclass"].isna()]
print(f"The number of valid geometries that have not yet been numbered：{len(unassigned)}")
print("success：")
print(gdf["geo_subclass"].value_counts())

# Difference detection (valid only)
# make sure the indexes of gdf_valid are continuous
gdf_valid = gdf_valid.reset_index(drop=True)

# filter
gdf_valid = gdf[gdf.geometry.notnull() & gdf.geometry.is_valid].copy()

# define
def compute_differences(df_group):
    ids = df_group["id"].values
    geometries = df_group.geometry.values
    flags = [False] * len(df_group)
    for i in range(len(ids)):
        for j in range(i + 1, len(ids)):
            c_dist = geometries[i].centroid.distance(geometries[j].centroid)
            a_diff = abs(geometries[i].area - geometries[j].area) / max(geometries[i].area, geometries[j].area)
            if c_dist < 10 and a_diff > 0.3:
                flags[i] = flags[j] = True
    return flags

# Group geo_subclass by geo_subclass and mark the differences
flags_all = []
for subclass in gdf_valid["geo_subclass"].dropna().unique():
    group = gdf_valid[gdf_valid["geo_subclass"] == subclass].copy()
    flags = compute_differences(group)
    flags_all.extend(flags)

if len(flags_all) != len(gdf_valid):
    gdf_valid["wrong"] = [False] * len(gdf_valid)
else:
    gdf_valid["wrong"] = flags_all


#  Merge the difference markers into the original gdf (keep invalid data)
gdf = gdf.drop(columns=["wrong"], errors="ignore")
gdf = gdf.merge(gdf_valid[["id", "wrong"]], on="id", how="left")

gdf.head(5)

#  export excel
output_rows = []
for subclass in sorted(gdf["geo_subclass"].dropna().unique()):
    group = gdf[gdf["geo_subclass"] == subclass]
    for i, (_, row) in enumerate(group.iterrows()):
        output_rows.append({
            "category": row["main_category"] if i == 0 else "",
            "sub": subclass if i == 0 else "",
            "response": row["Response"],
            "area (㎡)": round(row["area"], 2),
            "shape_index": round(row["shape_index"], 2),
            "wrong": row["wrong"],
            'geometry': row['geometry'],
            'OLCs': row['Open Location Code']
        })

output_df = pd.DataFrame(output_rows)
output_df.to_csv("./drive/MyDrive/apply_data_science/survey_data/output_location_differences.csv", index=False)

output_df.head()

# Only keep legal data + necessary fields
gdf_valid = gdf[gdf.is_valid_geom].copy()
gdf_valid = gdf_valid[["geometry", "geo_subclass", "main_category", "Response"]]

geojson_str = gdf_valid.to_json()
# Bokeh
source = GeoJSONDataSource(geojson=geojson_str)

# Get the subclass list and the color palette
subclass_list = gdf_valid["geo_subclass"].dropna().unique().tolist()
palette = Category20[min(len(subclass_list), 20)]

# mapping
p = figure(title="Geo Design Topology - EPSG:3857",
           tools="pan,wheel_zoom,reset,hover,save",
           width=1000, height=700,
           x_axis_type="mercator", y_axis_type="mercator")

# Loading Google Maps Tile as basemap
p.add_tile(WMTSTileSource(url='http://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}'))

# Draw graphics, fill color associated with subclass
p.patches('xs', 'ys', source=source,
          fill_alpha=0.5, line_color="black", line_width=0.5,
          fill_color=factor_cmap('geo_subclass', palette=palette, factors=subclass_list))

# setting
hover = p.select_one(HoverTool)
hover.tooltips = [
    ("sub", "@geo_subclass"),
    ("category", "@main_category"),
    ("response", "@Response")
]

# 输出 HTML 地图文件
output_file("bokeh_geo_subclass_map.html")
save(p)

# 打印成功信息
print("✅ HTML！")

